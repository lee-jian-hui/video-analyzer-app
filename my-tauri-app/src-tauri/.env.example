# Tauri Backend Configuration (Rust Layer)
# Copy this file to .env and customize for your environment
#
# Architecture:
#   Frontend (React) → Tauri (Rust Client) → Python gRPC Server
#
# This file configures the Rust/Tauri CLIENT that connects to Python backend

# ============================================================================
# Python Backend Connection
# ============================================================================

# URL of the Python gRPC server (backend)
# This is where your Python video analyzer server is running
# Default: http://127.0.0.1:50051 (same machine)
GRPC_SERVER_URL=http://127.0.0.1:50051

# Video chunk size for uploads (in bytes)
# Default: 524288 (512 KB)
# Larger values = fewer chunks but more memory usage
VIDEO_CHUNK_SIZE=524288

# ============================================================================
# Application Configuration
# ============================================================================

# Log level: trace, debug, info, warn, error
# Default: info
LOG_LEVEL=info

# Development mode flag
# Default: automatically detected (debug builds = true)
DEV=true

# ============================================================================
# Usage Examples
# ============================================================================

# Development (local server):
#   GRPC_SERVER_URL=http://127.0.0.1:50051
#
# Production (remote server):
#   GRPC_SERVER_URL=http://production-server.com:50051
#
# Custom port:
#   GRPC_SERVER_URL=http://127.0.0.1:8080
#
# Larger chunk size (1 MB):
#   VIDEO_CHUNK_SIZE=1048576
